{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import os \n",
    "from torchvision.datasets import SVHN \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import shutil\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GAN_LOGS = os.path.join(os.getcwd(), \"tboard_logs\", \"gan\")\n",
    "if not os.path.exists(GAN_LOGS):\n",
    "    os.makedirs(GAN_LOGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"imgs\"):\n",
    "    os.makedirs(\"imgs\")\n",
    "shutil.rmtree(\"imgs/training\")\n",
    "if not os.path.exists(\"imgs/training\"):\n",
    "    os.makedirs(\"imgs/training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=SVHN(split='train',root='data/train',transform=ToTensor())\n",
    "test_dataset=SVHN(split='test',root='data/test',transform=ToTensor())\n",
    "\n",
    "batch_size=16\n",
    "class_num=10\n",
    "channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(test_dataset, batch_size, num_workers=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_model_params(model):\n",
    "    \"\"\" Counting the number of learnable parameters in a nn.Module \"\"\"\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple convolutional block: Conv + Norm + Act + Dropout\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, add_norm=True, activation=\"ReLU\", dropout=None):\n",
    "        \"\"\" Module Initializer \"\"\"\n",
    "        super().__init__()\n",
    "        assert activation in [\"ReLU\", \"LeakyReLU\", \"Sigmoid\", \"Tanh\", None]\n",
    "        padding = kernel_size // 2\n",
    "        \n",
    "        block = []\n",
    "        block.append(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride))\n",
    "        if add_norm:\n",
    "            block.append(nn.BatchNorm2d(out_channels))\n",
    "        if activation is not None:\n",
    "            nonlinearity = getattr(nn, activation, nn.ReLU)()\n",
    "            if isinstance(nonlinearity, nn.LeakyReLU):\n",
    "                nonlinearity.negative_slope = 0.2\n",
    "            block.append(nonlinearity)\n",
    "            \n",
    "        if dropout is not None:\n",
    "            block.append(nn.Dropout(dropout))\n",
    "            \n",
    "        self.block =  nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass \"\"\"\n",
    "        y = self.block(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ConvTransposeBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple convolutional block: ConvTranspose + Norm + Act + Dropout\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, add_norm=True, activation=\"ReLU\", dropout=None):\n",
    "        \"\"\" Module Initializer \"\"\"\n",
    "        super().__init__()\n",
    "        assert activation in [\"ReLU\", \"LeakyReLU\", \"Tanh\", None]\n",
    "        padding = kernel_size // 2\n",
    "        \n",
    "        block = []\n",
    "        block.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, padding=1, stride=stride))\n",
    "        if add_norm:\n",
    "            block.append(nn.BatchNorm2d(out_channels))\n",
    "        if activation is not None:\n",
    "            nonlinearity = getattr(nn, activation, nn.ReLU)()\n",
    "            if isinstance(nonlinearity, nn.LeakyReLU):\n",
    "                nonlinearity.negative_slope = 0.2\n",
    "            block.append(nonlinearity)\n",
    "        if dropout is not None:\n",
    "            block.append(nn.Dropout(dropout))\n",
    "            \n",
    "        self.block =  nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass \"\"\"\n",
    "        y = self.block(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    \"\"\" Reshaping a vector in a given shape \"\"\"\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" \"\"\"\n",
    "        B, N = x.shape\n",
    "        x = x.view(B, N, 1, 1)\n",
    "        y = x.repeat(1, 1, *self.shape)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    A fully convolutional generator using ReLU activations. \n",
    "    Takes as input a latent vector and outputs a fake sample.\n",
    "       (B, latent_dim, 1, 1)  --> (B, num_channels, 32, 32)\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=128, num_channels=3, base_channels=32):\n",
    "        \"\"\" Model initializer \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(4):\n",
    "            layers.append(\n",
    "                ConvTransposeBlock(\n",
    "                        in_channels=latent_dim+class_num if i == 0 else base_channels * 2 ** (3-i+1),\n",
    "                        out_channels=base_channels * 2 ** (3-i),\n",
    "                        kernel_size=4,\n",
    "                        stride=1 if i == 0 else 2,\n",
    "                        add_norm=True,\n",
    "                        activation=\"ReLU\"\n",
    "                    )\n",
    "                )\n",
    "        layers.append(\n",
    "            ConvTransposeBlock(\n",
    "                    in_channels=base_channels,\n",
    "                    out_channels=num_channels,\n",
    "                    kernel_size=4,\n",
    "                    stride=2,\n",
    "                    add_norm=False,\n",
    "                    activation=\"Tanh\"\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        return\n",
    "    \n",
    "    def forward(self, x,labels):\n",
    "        \"\"\" Forward pass through generator \"\"\"\n",
    "        labels=labels.unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "        labels=labels.repeat(1,class_num,x.size(2),x.size(3))\n",
    "        x = torch.cat([x, labels], 1)\n",
    "        y = self.model(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim=128, num_channels=1, base_channels=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\" A fully convolutional discriminator using LeakyReLU activations. \n",
    "    Takes as input either a real or fake sample and predicts its autenticity.\n",
    "       (B, num_channels, 32, 32)  -->  (B, 1, 1, 1)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, out_dim=1, base_channels=32, dropout=0.3):\n",
    "        \"\"\" Module initializer \"\"\"\n",
    "        super().__init__()  \n",
    "        \n",
    "        layers = []\n",
    "        for i in range(4):\n",
    "            layers.append(\n",
    "                ConvBlock(\n",
    "                        in_channels=in_channels+class_num if i == 0 else base_channels * 2 ** i,\n",
    "                        out_channels=base_channels * 2 ** (i + 1),\n",
    "                        kernel_size=4,\n",
    "                        add_norm=True,\n",
    "                        activation=\"LeakyReLU\",\n",
    "                        dropout=dropout,\n",
    "                        stride=2\n",
    "                    )\n",
    "                )\n",
    "        layers.append(\n",
    "                ConvBlock(\n",
    "                        in_channels=base_channels * 16,\n",
    "                        out_channels=out_dim,\n",
    "                        kernel_size=4,\n",
    "                        stride=4,\n",
    "                        add_norm=False,\n",
    "                        activation=\"Sigmoid\"\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        return\n",
    "      \n",
    "    def forward(self, x,labels):\n",
    "        labels=labels.unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "        labels=labels.repeat(1,class_num,x.size(2),x.size(3))\n",
    "\n",
    "        # print(x.shape,labels.shape)\n",
    "        \"\"\" Forward pass \"\"\"\n",
    "        x = torch.cat([x, labels], 1)\n",
    "        y = self.model(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim=128, num_channels=1, base_channels=32)\n",
    "discriminator = Discriminator(in_channels=1, out_dim=1, base_channels=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Class for initializing GAN and training it\n",
    "    \"\"\"\n",
    "    def __init__(self, generator, discriminator,writer, latent_dim=128):\n",
    "        \"\"\" Initialzer \"\"\"\n",
    "        assert writer is not None, f\"Tensorboard writer not set...\"\n",
    "    \n",
    "        self.latent_dim = latent_dim\n",
    "        self.writer = writer \n",
    "        self.latent_dim = latent_dim\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.generator = generator.to(self.device)\n",
    "        self.discriminator = discriminator.to(self.device)\n",
    "        \n",
    "        self.optim_discriminator = torch.optim.Adam(self.discriminator.parameters(), lr=3e-4, betas=(0.5, 0.9))\n",
    "        self.optim_generator = torch.optim.Adam(self.generator.parameters(), lr=3e-4, betas=(0.5, 0.9))\n",
    "        \n",
    "        # REAL LABEL = 1\n",
    "        # FAKE LABEL = 0\n",
    "        # eps = 1e-10\n",
    "        # self.criterion_d_real = lambda pred: torch.clip(-torch.log(1 - pred + eps), min=-10).mean()\n",
    "        # self.criterion_d_fake = lambda pred: torch.clip(-torch.log(pred + eps), min=-10).mean()\n",
    "        # self.criterion_g = lambda pred: torch.clip(-torch.log(1 - pred + eps), min=-10).mean()\n",
    "        \n",
    "        self.criterion_d_real = lambda pred: F.binary_cross_entropy(pred, torch.ones(pred.shape[0], device=pred.device))\n",
    "        self.criterion_d_fake = lambda pred: F.binary_cross_entropy(pred, torch.zeros(pred.shape[0], device=pred.device))\n",
    "        self.criterion_g = lambda pred: F.binary_cross_entropy(pred, torch.ones(pred.shape[0], device=pred.device))\n",
    "        \n",
    "        self.hist = {\n",
    "            \"d_real\": [],\n",
    "            \"d_fake\": [],\n",
    "            \"g\": []\n",
    "        }\n",
    "        return\n",
    "        \n",
    "    def train_one_step(self, imgs,real_labels):\n",
    "        \"\"\" \n",
    "        raining both models for one optimization step\n",
    "        \"\"\"\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "        \n",
    "        # Sample from the latent distribution\n",
    "        B = imgs.shape[0]\n",
    "        latent = torch.randn(B, self.latent_dim, 1, 1).to(self.device)\n",
    "        fake_label=Variable(torch.LongTensor(np.random.randint(0, class_num, batch_size))).to(self.device)\n",
    "        # ==== Training Discriminator ====\n",
    "        self.optim_discriminator.zero_grad()\n",
    "        # Get discriminator outputs for the real samples\n",
    "        prediction_real = self.discriminator(imgs,real_labels)\n",
    "        # Compute the loss function\n",
    "        d_loss_real = self.criterion_d_real(prediction_real.view(B))\n",
    "\n",
    "        # Generating fake samples with the generator\n",
    "        fake_samples = self.generator(latent,fake_label)\n",
    "        # Get discriminator outputs for the fake samples\n",
    "        prediction_fake_d = self.discriminator(fake_samples.detach(),fake_label.detach())  # why detach?\n",
    "        # Compute the loss function\n",
    "        d_loss_fake = self.criterion_d_fake(prediction_fake_d.view(B))\n",
    "        (d_loss_real + d_loss_fake).backward()\n",
    "        assert fake_samples.shape == imgs.shape\n",
    "        \n",
    "        # optimization step\n",
    "        torch.nn.utils.clip_grad_norm_(self.discriminator.parameters(), 3.0)\n",
    "        self.optim_discriminator.step()\n",
    "        \n",
    "        # === Train the generator ===\n",
    "        self.optim_generator.zero_grad()\n",
    "        # Get discriminator outputs for the fake samples\n",
    "        prediction_fake_g = self.discriminator(fake_samples,fake_label)\n",
    "        # Compute the loss function\n",
    "        g_loss = self.criterion_g(prediction_fake_g.view(B))\n",
    "        g_loss.backward()\n",
    "        # optimization step\n",
    "        self.optim_generator.step()\n",
    "        \n",
    "        return d_loss_real, d_loss_fake, g_loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(self,N=2):\n",
    "        \"\"\" Generating a bunch of images using current state of generator \"\"\"\n",
    "        self.generator.eval()\n",
    "        latent = torch.randn(N, self.latent_dim, 1, 1).to(self.device)\n",
    "        fake_labels=torch.randint(0,class_num-1,(N,)).to(self.device)\n",
    "        imgs = self.generator(latent,fake_labels)\n",
    "        imgs = imgs * 0.5 + 0.5\n",
    "        return imgs\n",
    "        \n",
    "    def train(self, data_loader, N_iters=10000, init_step=0):\n",
    "        \"\"\" Training the models for several iterations \"\"\"\n",
    "        \n",
    "        progress_bar = tqdm(total=N_iters, initial=init_step)\n",
    "        running_d_loss = 0\n",
    "        running_g_loss = 0\n",
    "        \n",
    "        iter_ = 0\n",
    "        for i in range(N_iters):\n",
    "            print(f'epoch :{i}')\n",
    "            for real_batch,real_labels in data_loader:           \n",
    "                real_batch = real_batch.to(self.device)\n",
    "                real_labels = real_labels.to(self.device)\n",
    "                d_loss_real, d_loss_fake, g_loss = self.train_one_step(imgs=real_batch,real_labels=real_labels)\n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "            \n",
    "                # updating progress bar\n",
    "                progress_bar.set_description(f\"Ep {i+1} Iter {iter_}: D_Loss={round(d_loss.item(),5)}, G_Loss={round(g_loss.item(),5)})\")\n",
    "                self.writer.add_scalar(f'Loss/Generator Loss', g_loss.item(), global_step=iter_)\n",
    "                self.writer.add_scalar(f'Loss/Discriminator Loss', d_loss.item(), global_step=iter_)\n",
    "                self.writer.add_scalars(f'Loss/Discriminator Losses', {\n",
    "                        \"Real Images Loss\": d_loss_real.item(),\n",
    "                        \"Fake Images Loss\": d_loss_fake.item(),\n",
    "                    }, global_step=iter_)\n",
    "                self.writer.add_scalars(f'Comb_Loss/Losses', {\n",
    "                            'Discriminator': d_loss.item(),\n",
    "                            'Generator':  g_loss.item()\n",
    "                        }, iter_) \n",
    "\n",
    "    \n",
    "                # if(iter_ % 2000 == 0):\n",
    "                #     imgs = self.generate()\n",
    "                #     grid = torchvision.utils.make_grid(imgs, nrow=2)\n",
    "                #     torchvision.utils.save_image(grid, os.path.join(os.getcwd(), \"imgs\", \"training\", f\"imgs_{iter_}.png\"))\n",
    "\n",
    "                iter_ = iter_ + 1 \n",
    "                \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(GAN_LOGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim=128, num_channels=3, base_channels=32)\n",
    "discriminator = Discriminator(in_channels=3, out_dim=1, base_channels=32)\n",
    "count_model_params(generator),count_model_params(discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(generator=generator, discriminator=discriminator, latent_dim=128,writer=writer)\n",
    "trainer.train(data_loader=train_loader, N_iters=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynewenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
