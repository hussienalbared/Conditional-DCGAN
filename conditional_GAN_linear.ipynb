{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import os \n",
    "from torchvision.datasets import SVHN \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import save_image#\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "GAN_LOGS = os.path.join(os.getcwd(), \"tboard_logs\", \"gan\")\n",
    "if  os.path.exists(GAN_LOGS):\n",
    "    shutil.rmtree(GAN_LOGS)\n",
    "if not os.path.exists(GAN_LOGS):\n",
    "    os.makedirs(GAN_LOGS)\n",
    "\n",
    "writer = SummaryWriter(GAN_LOGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  os.path.exists(\"imgs/training\"):\n",
    "    shutil.rmtree(\"imgs/training\")\n",
    "\n",
    "if not os.path.exists(\"imgs/training\"):\n",
    "    os.makedirs(\"imgs/training\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        # transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=SVHN(split='train',root='data/train',transform=transform,download=True)\n",
    "# test_dataset=SVHN(split='test',root='data/test',transform=transform)\n",
    "\n",
    "# vars(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = {'0','1','2','3','4','5','6','7','8','9'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "\n",
    "img_size = 32 # Image size\n",
    "batch_size = 32  # Batch size\n",
    "\n",
    "# Model\n",
    "z_size = 100\n",
    "generator_layer_size = [128, 512, 1024]\n",
    "discriminator_layer_size = [1024, 512, 128]\n",
    "\n",
    "# Training\n",
    "epochs = 12  # Train epochs\n",
    "learning_rate = 1e-4\n",
    "class_num=10\n",
    "channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# val_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=next(iter(train_loader))\n",
    "a.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf8e8720990e3dbd63bc074b340d15ffc15ddd17"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, generator_layer_size, z_size, img_size, class_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.z_size = z_size\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.z_size + class_num, generator_layer_size[0]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[0], generator_layer_size[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[1], generator_layer_size[2]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[2], self.img_size * self.img_size*channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        \n",
    "        # Reshape z\n",
    "        z = z.view(-1, self.z_size)\n",
    "        \n",
    "        # One-hot vector to embedding vector\n",
    "        c = self.label_emb(labels)\n",
    "        \n",
    "        # Concat image & label\n",
    "        x = torch.cat([z, c], 1)\n",
    "        # Generator out\n",
    "        out = self.model(x)\n",
    "        \n",
    "        return out.view(-1,channels, self.img_size, self.img_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccef848d8bd24db1c12e5fec03cdafcf27468a59"
   },
   "source": [
    "## - Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83a994dc0acddf5d2a2ed1b706b88f6e308997dd"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, discriminator_layer_size, img_size, class_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.img_size * self.img_size*channels + class_num, discriminator_layer_size[0]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[0], discriminator_layer_size[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[1], discriminator_layer_size[2]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[2], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        \n",
    "        # Reshape fake image\n",
    "        x = x.view(-1, channels*self.img_size * self.img_size)\n",
    "        # One-hot vector to embedding vector\n",
    "        c = self.label_emb(labels)\n",
    "        \n",
    "        # Concat image & label\n",
    "        x = torch.cat([x, c], 1)\n",
    "        \n",
    "        # Discriminator out\n",
    "        out = self.model(x)\n",
    "        # return out\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d875fd305440b7572a3100bf4feae72ca57a8a5"
   },
   "outputs": [],
   "source": [
    "# Define generator\n",
    "generator = Generator(generator_layer_size, z_size, img_size, class_num).to(device)\n",
    "# Define discriminator\n",
    "discriminator = Discriminator(discriminator_layer_size, img_size, class_num).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Adversarial Learning of Generator & Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f3f7aa2d3d961df8623b93b3770b88f83bc77d0"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_d_real = lambda pred: F.binary_cross_entropy(pred, torch.ones(pred.shape[0], device=pred.device))\n",
    "criterion_d_fake = lambda pred: F.binary_cross_entropy(pred, torch.zeros(pred.shape[0], device=pred.device))\n",
    "criterion_g = lambda pred: F.binary_cross_entropy(pred, torch.ones(pred.shape[0], device=pred.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b976b9831f73e1d5da270c4050d380f4fe141933"
   },
   "outputs": [],
   "source": [
    "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
    "    \n",
    "    # Init gradient\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    # Building z\n",
    "    z = Variable(torch.randn(batch_size, z_size)).to(device)\n",
    "    \n",
    "    # Building fake labels\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, class_num, batch_size))).to(device)\n",
    "    \n",
    "    # Generating fake images\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # Disciminating fake images\n",
    "    validity = discriminator(fake_images, fake_labels)\n",
    "    # print(validity.shape)\n",
    "    # Calculating discrimination loss (fake images)\n",
    "    # g_loss = criterion(validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    # g_loss = criterion(validity, torch.ones(validity.shape[0], device=validity.device))\n",
    "    g_loss = criterion_g(validity.view(batch_size))\n",
    "    # Backword propagation\n",
    "    g_loss.backward()\n",
    "    \n",
    "    #  Optimizing generator\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return g_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce7aa31b594067c3e3c006944ca16e7cba2c5ed4"
   },
   "outputs": [],
   "source": [
    "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
    "    \n",
    "    # Init gradient \n",
    "    d_optimizer.zero_grad()\n",
    "    B = real_images.shape[0]\n",
    "\n",
    "    # Disciminating real images\n",
    "    real_validity = discriminator(real_images, labels)\n",
    "    \n",
    "    # Calculating discrimination loss (real images)\n",
    "    # real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    # real_loss = criterion(real_validity, torch.ones(real_validity.shape[0], device=real_validity.device))\n",
    "    real_loss =criterion_d_real(real_validity)\n",
    "    \n",
    "    # Building z\n",
    "    z = Variable(torch.randn(batch_size, z_size)).to(device)\n",
    "    \n",
    "    # Building fake labels\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, class_num, batch_size))).to(device)\n",
    "    \n",
    "    # Generating fake images\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # Disciminating fake images\n",
    "    fake_validity = discriminator(fake_images, fake_labels)\n",
    "    # print(fake_validity.shape)\n",
    "    \n",
    "    # Calculating discrimination loss (fake images)\n",
    "    # fake_loss = criterion(fake_validity, Variable(torch.zeros(batch_size)).to(device))\n",
    "    # fake_loss = criterion(fake_validity, torch.ones(fake_validity.shape[0], device=fake_validity.device))\n",
    "    fake_loss=criterion_d_fake(fake_validity.view(B))\n",
    "    # Sum two losses\n",
    "    d_loss = real_loss , fake_loss\n",
    "    (real_loss + fake_loss).backward()\n",
    "\n",
    "    \n",
    "    # Optimizing discriminator\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "_uuid": "f3c434a2dbc65b30dffa090ba0b51be3588763c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_gan(epochs,discriminator,train_loader,generator,g_optimizer=g_optimizer,batch_size=batch_size,d_optimizer=d_optimizer):\n",
    "    iter_ = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('Starting epoch {}...'.format(epoch+1))\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # Train data\n",
    "            real_images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "            \n",
    "            # Set generator train\n",
    "            generator.train()\n",
    "            \n",
    "            # Train discriminator\n",
    "            d_loss_real, d_loss_fake = discriminator_train_step(len(real_images), discriminator,\n",
    "                                            generator, d_optimizer, criterion,\n",
    "                                            real_images, labels)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            \n",
    "            # Train generator\n",
    "            g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
    "            writer.add_scalar(f'Loss/Generator Loss', g_loss.item(), global_step=iter_)\n",
    "            writer.add_scalar(f'Loss/Discriminator Loss', d_loss_real.item(), global_step=iter_)\n",
    "            writer.add_scalars(f'Loss/Discriminator Losses', {\n",
    "                        \"Real Images Loss\": d_loss_real.item(),\n",
    "                        \"Fake Images Loss\": d_loss_fake.item(),\n",
    "                    }, global_step=iter_)\n",
    "            writer.add_scalars(f'Comb_Loss/Losses', {\n",
    "                            'Discriminator': d_loss.item(),\n",
    "                            'Generator':  g_loss.item()\n",
    "                        }, iter_) \n",
    "            iter_=iter_+1\n",
    "        \n",
    "        # Set generator eval\n",
    "        # generator.eval()\n",
    "        \n",
    "            # print('g_loss: {}, d_loss: {}'.format(g_loss, d_loss))\n",
    "        \n",
    "        # Building z \n",
    "            z = Variable(torch.randn(class_num-1, z_size)).to(device)\n",
    "            \n",
    "            # Labels 0 ~ 8\n",
    "            labels = Variable(torch.LongTensor(np.arange(class_num-1))).to(device)\n",
    "            \n",
    "            # Generating images\n",
    "            sample_images = generator(z, labels).data.cpu()\n",
    "            # print(sample_images.shape)\n",
    "            # Show images\n",
    "            if(iter_ % 200 == 0):\n",
    "                grid = make_grid(sample_images, nrow=1, normalize=True)\n",
    "                # .permute(1,2,0).numpy()\n",
    "                writer.add_image('images', grid, global_step=iter_)\n",
    "                torchvision.utils.save_image(grid, os.path.join(os.getcwd(), \"imgs\", \"training\", f\"imgs_{iter_}.png\"))\n",
    "        # plt.imshow(grid)\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1...\n",
      "Starting epoch 2...\n",
      "Starting epoch 3...\n",
      "Starting epoch 4...\n",
      "Starting epoch 5...\n",
      "Starting epoch 6...\n",
      "Starting epoch 7...\n",
      "Starting epoch 8...\n",
      "Starting epoch 9...\n",
      "Starting epoch 10...\n",
      "Starting epoch 11...\n"
     ]
    }
   ],
   "source": [
    "train_gan(epochs=epochs,generator=generator,discriminator=discriminator,train_loader=train_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d87a0e53fb451a6cab5ad07f06d45eb8387644aa"
   },
   "source": [
    "## - Show Generating Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a143c8f12edf5fbe6e607185215fad39f8b932b"
   },
   "outputs": [],
   "source": [
    "# Building z \n",
    "z = Variable(torch.randn(z_size, z_size)).to(device)\n",
    "\n",
    "# Labels 0 ~ 9\n",
    "labels = Variable(torch.LongTensor([i for _ in range(class_num) for i in range(class_num)])).to(device)\n",
    "\n",
    "# Generating images\n",
    "sample_images = generator(z, labels).data.cpu()\n",
    "\n",
    "# Show images\n",
    "grid = make_grid(sample_images, nrow=class_num, normalize=True).permute(1,2,0).numpy()\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax.imshow(grid)\n",
    "_ = plt.yticks([])\n",
    "_ = plt.xticks(np.arange(15, 300, 30), class_list, rotation=45, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = Variable(torch.randn(100, 8)).to(device)\n",
    "\n",
    "# Labels 0 ~ 9\n",
    "tt=[5 for i in range(8)]\n",
    "labels2 = Variable(torch.LongTensor([i for i in  tt]) ).to(device)\n",
    "\n",
    "sample_images = generator(z2, labels2).data.cpu()\n",
    "\n",
    "# Show images\n",
    "grid = make_grid(sample_images, nrow=class_num, normalize=True).permute(1,2,0).numpy()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ax.imshow(grid)\n",
    "_ = plt.yticks([])\n",
    "_ = plt.xticks(np.arange(15, 300, 30), class_list, rotation=45, fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
