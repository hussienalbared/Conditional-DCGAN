{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import os \n",
    "from torchvision.datasets import SVHN \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        # transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': 'data/train',\n",
       " 'transform': Compose(\n",
       "     ToTensor()\n",
       "     Normalize(mean=(0.5,), std=(0.5,))\n",
       " ),\n",
       " 'target_transform': None,\n",
       " 'transforms': StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(0.5,))\n",
       "            ),\n",
       " 'split': 'train',\n",
       " 'url': 'http://ufldl.stanford.edu/housenumbers/train_32x32.mat',\n",
       " 'filename': 'train_32x32.mat',\n",
       " 'file_md5': 'e26dedcc434d2e4c54c9b2d4a06d8373',\n",
       " 'data': array([[[[ 33,  15,  15, ...,  72,  82,  89],\n",
       "          [ 28,  14,  14, ...,  40,  67,  83],\n",
       "          [ 40,  18,  16, ...,  23,  35,  72],\n",
       "          ...,\n",
       "          [ 86,  87,  82, ..., 104, 104, 103],\n",
       "          [ 84,  86,  82, ..., 110, 106, 106],\n",
       "          [ 85,  89,  85, ..., 111, 109, 103]],\n",
       " \n",
       "         [[ 30,  23,  17, ...,  65,  77,  79],\n",
       "          [ 39,  25,  20, ...,  39,  58,  78],\n",
       "          [ 41,  21,  17, ...,  29,  42,  69],\n",
       "          ...,\n",
       "          [ 81,  82,  79, ..., 104, 105, 105],\n",
       "          [ 86,  79,  76, ..., 103, 105, 104],\n",
       "          [ 88,  82,  79, ..., 104, 105, 106]],\n",
       " \n",
       "         [[ 38,  19,  19, ...,  56,  57,  59],\n",
       "          [ 35,  22,  17, ...,  50,  52,  60],\n",
       "          [ 38,  26,  23, ...,  45,  44,  53],\n",
       "          ...,\n",
       "          [ 75,  71,  65, ...,  87,  81,  78],\n",
       "          [ 64,  72,  72, ...,  84,  85,  86],\n",
       "          [ 68,  72,  67, ...,  87,  86,  79]]],\n",
       " \n",
       " \n",
       "        [[[ 84,  86,  77, ...,  90,  88,  88],\n",
       "          [ 85,  83,  74, ...,  89,  88,  88],\n",
       "          [ 83,  78,  61, ...,  90,  88,  85],\n",
       "          ...,\n",
       "          [100,  98,  95, ..., 104, 102, 100],\n",
       "          [103, 106, 103, ..., 103, 103, 105],\n",
       "          [103, 103, 104, ..., 113, 104, 103]],\n",
       " \n",
       "         [[ 76,  73,  78, ...,  78,  77,  78],\n",
       "          [ 77,  73,  69, ...,  82,  79,  81],\n",
       "          [ 76,  77,  50, ...,  85,  83,  82],\n",
       "          ...,\n",
       "          [ 98,  94,  93, ..., 104, 102, 101],\n",
       "          [104, 104, 103, ..., 104, 103,  99],\n",
       "          [106, 105, 106, ..., 103, 104,  98]],\n",
       " \n",
       "         [[ 59,  66,  56, ...,  69,  67,  66],\n",
       "          [ 61,  64,  59, ...,  64,  70,  67],\n",
       "          [ 60,  58,  54, ...,  63,  66,  70],\n",
       "          ...,\n",
       "          [ 72,  76,  73, ...,  86,  87,  78],\n",
       "          [ 79,  79,  87, ...,  86,  87,  81],\n",
       "          [ 82,  87,  91, ...,  88,  88,  80]]],\n",
       " \n",
       " \n",
       "        [[[ 19,  20,  25, ...,  65,  78,  98],\n",
       "          [ 21,  19,  25, ...,  63,  91, 130],\n",
       "          [ 21,  20,  22, ...,  79, 125, 178],\n",
       "          ...,\n",
       "          [ 88,  89,  84, ...,  62,  67,  74],\n",
       "          [ 88,  87,  88, ...,  60,  61,  65],\n",
       "          [ 84,  81,  87, ...,  63,  62,  63]],\n",
       " \n",
       "         [[ 54,  52,  57, ..., 144, 148, 158],\n",
       "          [ 53,  52,  56, ..., 137, 153, 180],\n",
       "          [ 53,  51,  52, ..., 147, 181, 218],\n",
       "          ...,\n",
       "          [162, 163, 156, ..., 142, 144, 145],\n",
       "          [164, 160, 159, ..., 141, 141, 143],\n",
       "          [160, 154, 158, ..., 144, 143, 145]],\n",
       " \n",
       "         [[110, 111, 116, ..., 223, 218, 220],\n",
       "          [110, 106, 111, ..., 208, 214, 229],\n",
       "          [110, 106, 106, ..., 210, 230, 254],\n",
       "          ...,\n",
       "          [237, 238, 230, ..., 227, 226, 225],\n",
       "          [240, 237, 237, ..., 230, 228, 226],\n",
       "          [238, 233, 238, ..., 235, 232, 231]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 92,  94, 114, ..., 200, 192, 190],\n",
       "          [ 92,  93, 111, ..., 181, 177, 183],\n",
       "          [ 99,  94, 107, ..., 167, 172, 185],\n",
       "          ...,\n",
       "          [ 99,  96, 108, ..., 210, 206, 203],\n",
       "          [ 94,  94, 110, ..., 219, 218, 212],\n",
       "          [ 88,  85, 105, ..., 217, 221, 218]],\n",
       " \n",
       "         [[ 78,  82, 101, ..., 201, 193, 191],\n",
       "          [ 78,  80,  98, ..., 180, 176, 182],\n",
       "          [ 84,  81,  94, ..., 166, 171, 184],\n",
       "          ...,\n",
       "          [ 94,  91, 103, ..., 207, 202, 197],\n",
       "          [ 91,  91, 107, ..., 218, 215, 209],\n",
       "          [ 87,  84, 103, ..., 217, 220, 217]],\n",
       " \n",
       "         [[101, 105, 125, ..., 203, 195, 193],\n",
       "          [103, 106, 124, ..., 184, 180, 187],\n",
       "          [112, 110, 123, ..., 171, 176, 189],\n",
       "          ...,\n",
       "          [110, 109, 124, ..., 204, 200, 199],\n",
       "          [103, 104, 121, ..., 215, 212, 209],\n",
       "          [ 94,  93, 114, ..., 214, 219, 218]]],\n",
       " \n",
       " \n",
       "        [[[190, 205, 220, ..., 229, 229, 229],\n",
       "          [183, 200, 218, ..., 227, 227, 228],\n",
       "          [171, 189, 213, ..., 231, 229, 227],\n",
       "          ...,\n",
       "          [187, 204, 217, ..., 204, 196, 196],\n",
       "          [186, 198, 211, ..., 222, 214, 208],\n",
       "          [190, 199, 208, ..., 232, 226, 218]],\n",
       " \n",
       "         [[188, 203, 218, ..., 231, 229, 228],\n",
       "          [182, 199, 217, ..., 228, 226, 224],\n",
       "          [170, 189, 213, ..., 230, 226, 223],\n",
       "          ...,\n",
       "          [185, 202, 217, ..., 200, 193, 193],\n",
       "          [184, 197, 211, ..., 216, 209, 205],\n",
       "          [188, 197, 208, ..., 227, 221, 213]],\n",
       " \n",
       "         [[191, 206, 220, ..., 224, 224, 223],\n",
       "          [186, 201, 218, ..., 223, 222, 221],\n",
       "          [175, 193, 215, ..., 226, 223, 220],\n",
       "          ...,\n",
       "          [186, 199, 210, ..., 195, 189, 189],\n",
       "          [185, 194, 204, ..., 212, 205, 200],\n",
       "          [190, 194, 201, ..., 223, 216, 209]]],\n",
       " \n",
       " \n",
       "        [[[216, 221, 226, ..., 200, 193, 197],\n",
       "          [204, 210, 220, ..., 201, 195, 196],\n",
       "          [198, 202, 212, ..., 203, 198, 195],\n",
       "          ...,\n",
       "          [233, 230, 228, ..., 198, 184, 189],\n",
       "          [231, 229, 227, ..., 195, 181, 186],\n",
       "          [230, 230, 229, ..., 190, 178, 181]],\n",
       " \n",
       "         [[217, 222, 227, ..., 199, 188, 189],\n",
       "          [205, 211, 221, ..., 199, 191, 190],\n",
       "          [198, 202, 211, ..., 200, 194, 190],\n",
       "          ...,\n",
       "          [226, 224, 223, ..., 196, 183, 187],\n",
       "          [226, 224, 223, ..., 194, 181, 183],\n",
       "          [226, 226, 225, ..., 190, 177, 178]],\n",
       " \n",
       "         [[212, 217, 221, ..., 191, 182, 186],\n",
       "          [202, 208, 217, ..., 193, 186, 186],\n",
       "          [197, 201, 210, ..., 196, 191, 187],\n",
       "          ...,\n",
       "          [228, 225, 221, ..., 190, 177, 182],\n",
       "          [228, 225, 222, ..., 186, 173, 177],\n",
       "          [227, 227, 226, ..., 181, 169, 171]]]], dtype=uint8),\n",
       " 'labels': array([1, 9, 2, ..., 1, 6, 9])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset=SVHN(split='train',root='data/train',transform=transform)\n",
    "# test_dataset=SVHN(split='test',root='data/test',transform=transform)\n",
    "\n",
    "vars(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = {'0','1','2','3','4','5','6','7','8','9'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "\n",
    "img_size = 32 # Image size\n",
    "batch_size = 8  # Batch size\n",
    "\n",
    "# Model\n",
    "z_size = 100\n",
    "generator_layer_size = [256, 512, 1024]\n",
    "discriminator_layer_size = [1024, 512, 256]\n",
    "\n",
    "# Training\n",
    "epochs = 30  # Train epochs\n",
    "learning_rate = 1e-4\n",
    "class_num=10\n",
    "channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# val_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=next(iter(train_loader))\n",
    "a.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf8e8720990e3dbd63bc074b340d15ffc15ddd17"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, generator_layer_size, z_size, img_size, class_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.z_size = z_size\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.z_size + class_num, generator_layer_size[0]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[0], generator_layer_size[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[1], generator_layer_size[2]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[2], self.img_size * self.img_size*channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        \n",
    "        # Reshape z\n",
    "        z = z.view(-1, self.z_size)\n",
    "        \n",
    "        # One-hot vector to embedding vector\n",
    "        c = self.label_emb(labels)\n",
    "        \n",
    "        # Concat image & label\n",
    "        x = torch.cat([z, c], 1)\n",
    "        # print(x.shape)\n",
    "        # Generator out\n",
    "        out = self.model(x)\n",
    "        \n",
    "        return out.view(-1,channels, self.img_size, self.img_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccef848d8bd24db1c12e5fec03cdafcf27468a59"
   },
   "source": [
    "## - Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83a994dc0acddf5d2a2ed1b706b88f6e308997dd"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, discriminator_layer_size, img_size, class_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.img_size * self.img_size*channels + class_num, discriminator_layer_size[0]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[0], discriminator_layer_size[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[1], discriminator_layer_size[2]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[2], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        \n",
    "        # Reshape fake image\n",
    "        x = x.view(-1, channels*self.img_size * self.img_size)\n",
    "        # print(x.shape)\n",
    "        # One-hot vector to embedding vector\n",
    "        c = self.label_emb(labels)\n",
    "        # print(c.shape)\n",
    "        \n",
    "        # Concat image & label\n",
    "        x = torch.cat([x, c], 1)\n",
    "        \n",
    "        # Discriminator out\n",
    "        out = self.model(x)\n",
    "        \n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d875fd305440b7572a3100bf4feae72ca57a8a5"
   },
   "outputs": [],
   "source": [
    "# Define generator\n",
    "generator = Generator(generator_layer_size, z_size, img_size, class_num).to(device)\n",
    "# Define discriminator\n",
    "discriminator = Discriminator(discriminator_layer_size, img_size, class_num).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Adversarial Learning of Generator & Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f3f7aa2d3d961df8623b93b3770b88f83bc77d0"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b976b9831f73e1d5da270c4050d380f4fe141933"
   },
   "outputs": [],
   "source": [
    "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
    "    \n",
    "    # Init gradient\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    # Building z\n",
    "    z = Variable(torch.randn(batch_size, z_size)).to(device)\n",
    "    \n",
    "    # Building fake labels\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, class_num, batch_size))).to(device)\n",
    "    \n",
    "    # Generating fake images\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # Disciminating fake images\n",
    "    validity = discriminator(fake_images, fake_labels)\n",
    "    \n",
    "    # Calculating discrimination loss (fake images)\n",
    "    g_loss = criterion(validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    \n",
    "    # Backword propagation\n",
    "    g_loss.backward()\n",
    "    \n",
    "    #  Optimizing generator\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return g_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce7aa31b594067c3e3c006944ca16e7cba2c5ed4"
   },
   "outputs": [],
   "source": [
    "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
    "    \n",
    "    # Init gradient \n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    # Disciminating real images\n",
    "    real_validity = discriminator(real_images, labels)\n",
    "    \n",
    "    # Calculating discrimination loss (real images)\n",
    "    real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    \n",
    "    # Building z\n",
    "    z = Variable(torch.randn(batch_size, z_size)).to(device)\n",
    "    \n",
    "    # Building fake labels\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, class_num, batch_size))).to(device)\n",
    "    \n",
    "    # Generating fake images\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # Disciminating fake images\n",
    "    fake_validity = discriminator(fake_images, fake_labels)\n",
    "    \n",
    "    # Calculating discrimination loss (fake images)\n",
    "    fake_loss = criterion(fake_validity, Variable(torch.zeros(batch_size)).to(device))\n",
    "    \n",
    "    # Sum two losses\n",
    "    d_loss = real_loss + fake_loss\n",
    "    \n",
    "    # Backword propagation\n",
    "    d_loss.backward()\n",
    "    \n",
    "    # Optimizing discriminator\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3c434a2dbc65b30dffa090ba0b51be3588763c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_gan(epochs,discriminator,train_loader,generator,g_optimizer=g_optimizer,batch_size=batch_size,d_optimizer=d_optimizer):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('Starting epoch {}...'.format(epoch+1))\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # Train data\n",
    "            real_images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "            \n",
    "            # Set generator train\n",
    "            generator.train()\n",
    "            \n",
    "            # Train discriminator\n",
    "            d_loss = discriminator_train_step(len(real_images), discriminator,\n",
    "                                            generator, d_optimizer, criterion,\n",
    "                                            real_images, labels)\n",
    "            \n",
    "            # Train generator\n",
    "            g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
    "        \n",
    "        # Set generator eval\n",
    "        generator.eval()\n",
    "        \n",
    "        print('g_loss: {}, d_loss: {}'.format(g_loss, d_loss))\n",
    "        \n",
    "        # Building z \n",
    "        z = Variable(torch.randn(class_num-1, z_size)).to(device)\n",
    "        \n",
    "        # Labels 0 ~ 8\n",
    "        labels = Variable(torch.LongTensor(np.arange(class_num-1))).to(device)\n",
    "        \n",
    "        # Generating images\n",
    "        sample_images = generator(z, labels).data.cpu()\n",
    "        print(sample_images.shape)\n",
    "        # Show images\n",
    "        grid = make_grid(sample_images, nrow=3, normalize=True).permute(1,2,0).numpy()\n",
    "        plt.imshow(grid)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(epochs=epochs,generator=generator,discriminator=discriminator,train_loader=train_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d87a0e53fb451a6cab5ad07f06d45eb8387644aa"
   },
   "source": [
    "## - Show Generating Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a143c8f12edf5fbe6e607185215fad39f8b932b"
   },
   "outputs": [],
   "source": [
    "# Building z \n",
    "z = Variable(torch.randn(z_size, z_size)).to(device)\n",
    "\n",
    "# Labels 0 ~ 9\n",
    "labels = Variable(torch.LongTensor([i for _ in range(class_num*2) for i in range(class_num)])).to(device)\n",
    "\n",
    "# Generating images\n",
    "sample_images = generator(z, labels).data.cpu()\n",
    "\n",
    "# Show images\n",
    "grid = make_grid(sample_images, nrow=class_num, normalize=True).permute(1,2,0).numpy()\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax.imshow(grid)\n",
    "_ = plt.yticks([])\n",
    "_ = plt.xticks(np.arange(15, 300, 30), class_list, rotation=45, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(2, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
