{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from torchvision.datasets import SVHN \n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import save_image#\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "GAN_LOGS = os.path.join(os.getcwd(), \"tboard_logs\", \"gan\")\n",
    "if  os.path.exists(GAN_LOGS):\n",
    "    shutil.rmtree(GAN_LOGS)\n",
    "if not os.path.exists(GAN_LOGS):\n",
    "    os.makedirs(GAN_LOGS)\n",
    "\n",
    "writer = SummaryWriter(GAN_LOGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  os.path.exists(\"imgs/training\"):\n",
    "    shutil.rmtree(\"imgs/training\")\n",
    "\n",
    "if not os.path.exists(\"imgs/training\"):\n",
    "    os.makedirs(\"imgs/training\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        # transforms.Grayscale(),\n",
    "        # transforms.Resize(128),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=SVHN(split='train',root='data/train',transform=transform,download=False)\n",
    "# test_dataset=SVHN(split='test',root='data/test',transform=transform)\n",
    "\n",
    "# vars(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = {'0','1','2','3','4','5','6','7','8','9'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "\n",
    "img_size = 32 # Image size\n",
    "batch_size = 64  # Batch size\n",
    "\n",
    "# Model\n",
    "z_size = 500\n",
    "generator_layer_size = [128, 512, 1024]\n",
    "discriminator_layer_size = [1024, 512, 128]\n",
    "\n",
    "# Training\n",
    "epochs = 50  # Train epochs\n",
    "learning_rate = 1e-4\n",
    "class_num=10\n",
    "channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "# val_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=next(iter(train_loader))\n",
    "a.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf8e8720990e3dbd63bc074b340d15ffc15ddd17"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, generator_layer_size, z_size, img_size, class_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.z_size = z_size\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.z_size + class_num, generator_layer_size[0]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[0], generator_layer_size[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[1], generator_layer_size[2]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[2], self.img_size * self.img_size*channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        \n",
    "        # Reshape z\n",
    "        z = z.view(-1, self.z_size)\n",
    "        \n",
    "        # One-hot vector to embedding vector\n",
    "        c = self.label_emb(labels)\n",
    "        \n",
    "        # Concat image & label\n",
    "        x = torch.cat([z, c], 1)\n",
    "        # Generator out\n",
    "        out = self.model(x)\n",
    "        \n",
    "        return out.view(-1,channels, self.img_size, self.img_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccef848d8bd24db1c12e5fec03cdafcf27468a59"
   },
   "source": [
    "## - Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83a994dc0acddf5d2a2ed1b706b88f6e308997dd"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, discriminator_layer_size, img_size, class_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.img_size * self.img_size*channels + class_num, discriminator_layer_size[0]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[0], discriminator_layer_size[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[1], discriminator_layer_size[2]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[2], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        \n",
    "        # Reshape fake image\n",
    "        x = x.view(-1, channels*self.img_size * self.img_size)\n",
    "        # One-hot vector to embedding vector\n",
    "        c = self.label_emb(labels)\n",
    "        \n",
    "        # Concat image & label\n",
    "        x = torch.cat([x, c], 1)\n",
    "        \n",
    "        # Discriminator out\n",
    "        out = self.model(x)\n",
    "        # return out\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d875fd305440b7572a3100bf4feae72ca57a8a5"
   },
   "outputs": [],
   "source": [
    "# Define generator\n",
    "generator = Generator(generator_layer_size, z_size, img_size, class_num).to(device)\n",
    "# Define discriminator\n",
    "discriminator = Discriminator(discriminator_layer_size, img_size, class_num).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Adversarial Learning of Generator & Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f3f7aa2d3d961df8623b93b3770b88f83bc77d0"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_d_real = lambda pred: F.binary_cross_entropy(pred, torch.ones(pred.shape[0], device=pred.device))\n",
    "criterion_d_fake = lambda pred: F.binary_cross_entropy(pred, torch.zeros(pred.shape[0], device=pred.device))\n",
    "criterion_g = lambda pred: F.binary_cross_entropy(pred, torch.ones(pred.shape[0], device=pred.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b976b9831f73e1d5da270c4050d380f4fe141933"
   },
   "outputs": [],
   "source": [
    "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
    "    \n",
    "    # Init gradient\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    # Building z\n",
    "    z = Variable(torch.randn(batch_size, z_size)).to(device)\n",
    "    \n",
    "    # Building fake labels\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, class_num, batch_size))).to(device)\n",
    "    \n",
    "    # Generating fake images\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # Disciminating fake images\n",
    "    validity = discriminator(fake_images, fake_labels)\n",
    "    # print(validity.shape)\n",
    "    # Calculating discrimination loss (fake images)\n",
    "    # g_loss = criterion(validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    # g_loss = criterion(validity, torch.ones(validity.shape[0], device=validity.device))\n",
    "    g_loss = criterion_g(validity.view(batch_size))\n",
    "    # Backword propagation\n",
    "    g_loss.backward()\n",
    "    \n",
    "    #  Optimizing generator\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return g_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce7aa31b594067c3e3c006944ca16e7cba2c5ed4"
   },
   "outputs": [],
   "source": [
    "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
    "    \n",
    "    # Init gradient \n",
    "    d_optimizer.zero_grad()\n",
    "    B = real_images.shape[0]\n",
    "\n",
    "    # Disciminating real images\n",
    "    real_validity = discriminator(real_images, labels)\n",
    "    \n",
    "    # Calculating discrimination loss (real images)\n",
    "    # real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    # real_loss = criterion(real_validity, torch.ones(real_validity.shape[0], device=real_validity.device))\n",
    "    real_loss =criterion_d_real(real_validity)\n",
    "    \n",
    "    # Building z\n",
    "    z = Variable(torch.randn(batch_size, z_size)).to(device)\n",
    "    \n",
    "    # Building fake labels\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, class_num, batch_size))).to(device)\n",
    "    \n",
    "    # Generating fake images\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # Disciminating fake images\n",
    "    fake_validity = discriminator(fake_images, fake_labels)\n",
    "    # print(fake_validity.shape)\n",
    "    \n",
    "    # Calculating discrimination loss (fake images)\n",
    "    # fake_loss = criterion(fake_validity, Variable(torch.zeros(batch_size)).to(device))\n",
    "    # fake_loss = criterion(fake_validity, torch.ones(fake_validity.shape[0], device=fake_validity.device))\n",
    "    fake_loss=criterion_d_fake(fake_validity.view(B))\n",
    "    # Sum two losses\n",
    "    d_loss = real_loss , fake_loss\n",
    "    (real_loss + fake_loss).backward()\n",
    "\n",
    "    \n",
    "    # Optimizing discriminator\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3c434a2dbc65b30dffa090ba0b51be3588763c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_gan(epochs,discriminator,train_loader,generator,g_optimizer=g_optimizer,batch_size=batch_size,d_optimizer=d_optimizer):\n",
    "    iter_ = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('Starting epoch {}...'.format(epoch+1))\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # Train data\n",
    "            real_images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "            \n",
    "            # Set generator train\n",
    "            generator.train()\n",
    "            \n",
    "            # Train discriminator\n",
    "            d_loss_real, d_loss_fake = discriminator_train_step(len(real_images), discriminator,\n",
    "                                            generator, d_optimizer, criterion,\n",
    "                                            real_images, labels)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            \n",
    "            # Train generator\n",
    "            g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
    "            writer.add_scalar(f'Loss/Generator Loss', g_loss.item(), global_step=iter_)\n",
    "            writer.add_scalar(f'Loss/Discriminator Loss', d_loss_real.item(), global_step=iter_)\n",
    "            writer.add_scalars(f'Loss/Discriminator Losses', {\n",
    "                        \"Real Images Loss\": d_loss_real.item(),\n",
    "                        \"Fake Images Loss\": d_loss_fake.item(),\n",
    "                    }, global_step=iter_)\n",
    "            writer.add_scalars(f'Comb_Loss/Losses', {\n",
    "                            'Discriminator': d_loss.item(),\n",
    "                            'Generator':  g_loss.item()\n",
    "                        }, iter_) \n",
    "            iter_=iter_+1\n",
    "        \n",
    "        # Set generator eval\n",
    "        # generator.eval()\n",
    "        \n",
    "            # print('g_loss: {}, d_loss: {}'.format(g_loss, d_loss))\n",
    "        \n",
    "        # Building z \n",
    "\n",
    "            # print(sample_images.shape)\n",
    "            # Show images\n",
    "            if(iter_ % 2000 == 0):\n",
    "                with torch.no_grad():\n",
    "                    generator.eval()\n",
    "                    z__ = Variable(torch.randn(class_num-1, z_size)).to(device)\n",
    "                \n",
    "                # Labels 0 ~ 9\n",
    "                    labels__ = Variable(torch.LongTensor(np.arange(class_num-1))).to(device)\n",
    "                    plt.figure(figsize=(6,6))\n",
    "                \n",
    "                # Generating images\n",
    "                    sample_images = generator(z__, labels__).data.cpu()\n",
    "                    grid = make_grid(sample_images, nrow=4, normalize=True)\n",
    "                    # .permute(1,2,0).numpy()\n",
    "                    writer.add_image('images', grid, global_step=iter_)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(os.getcwd(), \"imgs\", \"training\", f\"imgs_{iter_}.png\"))\n",
    "                  # \n",
    "                    plt.imshow(grid.permute(1,2,0).numpy())\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(epochs=epochs,generator=generator,discriminator=discriminator,train_loader=train_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d87a0e53fb451a6cab5ad07f06d45eb8387644aa"
   },
   "source": [
    "## - Show Generating Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = Variable(torch.randn(z_size, 9)).to(device)\n",
    "\n",
    "# Labels 0 ~ 9\n",
    "tt=[i for i in range(9)]\n",
    "labels2 = Variable(torch.LongTensor([i for i in  tt]) ).to(device)\n",
    "\n",
    "sample_images = generator(z2, labels2).data.cpu()\n",
    "\n",
    "# Show images\n",
    "grid = make_grid(sample_images, nrow=3, normalize=True, scale_each=True).permute(1,2,0).numpy()\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.imshow(grid)\n",
    "_ = plt.yticks([])\n",
    "# _ = plt.xticks(np.arange(15, 300, 30), class_list, rotation=45, fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
